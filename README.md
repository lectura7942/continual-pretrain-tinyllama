# continual-pretrain-tinyllama

μ¶”κ°€ μ‚¬μ „ν•™μµ μ‹¤μµμ© μ½”λ“μ…λ‹λ‹¤. μμ„Έν• μ„¤λ…μ€ λ‹¤μ κΈ€μ„ μ°Έκ³ ν•κΈΈ λ°”λλ‹λ‹¤: [κΈ€ λ§ν¬](https://jkspace.notion.site/11-20-238b1a84a5a9409fb895ce349fef85e1?pvs=4)

λ³Έ μ‹¤μµμ—μ„λ”

1. ν•κµ­μ–΄ λ‰΄μ¤ λ°μ΄ν„°λ΅ μ‚¬μ „ν•™μµμ„ ν•κ³ 
2. μƒλ‹΄ λ°μ΄ν„°λ΅ μ¶”κ°€ μ‚¬μ „ν•™μµ(Continual Pretraining)μ„ ν•΄λ„
3. μ²« λ²μ§Έ λ„λ©”μΈ(λ‰΄μ¤ λ°μ΄ν„°)μ— λ€ν• μ •λ³΄λ¥Ό λ¨λΈμ΄ μ κΈ°μ–µν•κ³  μλ”μ§€ ν™•μΈν•λ” κ²ƒμ„ λ©ν‘λ΅ ν•©λ‹λ‹¤.
   
π“ νΉν Colabμ—μ„ λλ¦΄ λ•, HuggingFace (μ΄ν•, HF) Hubμ— λ°μ΄ν„°μ…‹, μ²΄ν¬ν¬μΈνΈλ¥Ό λ°±μ—…ν•λ” κ²ƒμ„ κ¶μ¥ν•©λ‹λ‹¤.

λ‹¤μ λ°μ΄ν„°μ…‹μ„ μ‚¬μ©ν•©λ‹λ‹¤. μ΄λ―Έ μ‚¬μ „ν•™μµμ„ μ„ν•΄ μ²­ν¬λ΅ λ‚λ„μ—κ³ , ν† ν°ν™”ν• λ°μ΄ν„°μ…‹μ…λ‹λ‹¤.
λ°©λ²• λ° μ½”λ“λ” `Continual_Pretraining_With_TinyLlama_120M.ipynb`μ `Create Dataset` μ„Ήμ…μ—μ„ λ³Ό μ μμµλ‹λ‹¤.

* μ²« λ²μ§Έ μ‚¬μ „ν•™μµ λ°μ΄ν„°μ…‹ HF repo: [lectura/naver_news_1024](https://huggingface.co/datasets/lectura/naver_news_1024)
* λ‘ λ²μ§Έ μ‚¬μ „ν•™μµ λ°μ΄ν„°μ…‹ HF repo: [lectura/counsel-ko_1024](https://huggingface.co/datasets/lectura/counsel-ko_1024)

ν† ν¬λ‚μ΄μ €λ” μ΄λ―Έ ν•κµ­μ–΄λ΅ ν•™μµλ κ²ƒμ„ μ‚¬μ©ν•©λ‹λ‹¤.

* ν† ν¬λ‚μ΄μ € HF repo: [beomi/llama-2-ko-7b](https://huggingface.co/beomi/llama-2-ko-7b)


